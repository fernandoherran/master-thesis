{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D slices extraction\n",
    "This notebook is used to extract PNG images from MRI files (with nifti format), which will be used to train a convolutional neural network.  \n",
    "\n",
    "The process is as follows:\n",
    "   - Load Nifti file\n",
    "   - Skull stripping\n",
    "   - Get slices from coronal view\n",
    "   - Add slices in a 2D picture\n",
    "   - Save picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify if user is working on Google Drive\n",
    "google_drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_drive == True:\n",
    "    \n",
    "    from google.colab import drive \n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    path = \"./drive/MyDrive/TFM\"\n",
    "    \n",
    "    import sys\n",
    "    sys.path.append(path)\n",
    "\n",
    "else:\n",
    "    path = \".\"\n",
    "    \n",
    "    import sys\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab TPU session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify if user is working on a TPU session in Google Colab\n",
    "tpu_session = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tpu_session == True:\n",
    "    \n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "    print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Neuroimaging packages\n",
    "import nibabel as nib # Access to neuroimaging data formats\n",
    "import med2image    # Convert medical images to jpg and png (pip install med2image)\n",
    "from scipy import ndimage\n",
    "\n",
    "# Extra utils\n",
    "from aux_functions.aux_functions_cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Nifti files - Extract 2D slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where there are the 3D zipped Nifti files of the brain \n",
    "root_nifti_files = [\"/datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_3\",\n",
    "                    \"/datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_4\",\n",
    "                    \"/datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_5\"]\n",
    "root_nifti_files = [path + item_ for item_ in root_nifti_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where to save the 2D slices in PNG format\n",
    "root_png_images = path + \"/datasets/New_png_images\"\n",
    "\n",
    "# Check if folder where to save the slices exists. If not, create it.\n",
    "if not os.path.exists(root_png_images):\n",
    "    os.mkdir(root_png_images)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract 2D slice from each Nitfi file\n",
    "  - Titles of the 3D nitfi files have this format: *ADNI_137_S_0283_MR_MPR-R__GradWarp__N3__Scaled_Br_20070810182546038_S31798_I67027.nii.gz*\n",
    "      - Last item **_\"I67027\"_** of the file name specifies the Image ID, which will be used later on the project.\n",
    "  - 3D Nitfi files have three planes:\n",
    "      - 1st axis - **AXIAL**\n",
    "      - 2nd axis - **CORONAL**\n",
    "      - 3rd axis - **SAGGITAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Folder: {'./datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_1'}\n",
      "    [-] Number of files in the folder: 131\n",
      "        20 images loaded\n",
      "        40 images loaded\n",
      "        60 images loaded\n",
      "        80 images loaded\n",
      "        100 images loaded\n",
      "        120 images loaded\n",
      "    [-] Number of images loaded: 131\n",
      "    [-] Shapes of images loaded: [(256, 256, 166), 48, (192, 192, 160), 49, (256, 256, 170), 12, (256, 256, 180), 18, (256, 256, 184), 4]\n",
      "WARNING:tensorflow:From /Users/nando/opt/anaconda3/lib/python3.8/site-packages/deepbrain/extractor.py:19: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "        20 images converted to PNG\n",
      "        40 images converted to PNG\n",
      "        60 images converted to PNG\n",
      "        80 images converted to PNG\n",
      "        100 images converted to PNG\n",
      "        120 images converted to PNG\n",
      "    [-] Number of images converted to PNG: 131\n",
      "[+] Folder: {'./datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_2'}\n",
      "    [-] Number of files in the folder: 128\n",
      "        20 images loaded\n",
      "        40 images loaded\n",
      "        60 images loaded\n",
      "        80 images loaded\n",
      "        100 images loaded\n",
      "        120 images loaded\n",
      "    [-] Number of images loaded: 127\n",
      "    [-] Shapes of images loaded: [(256, 256, 166), 44, (192, 192, 160), 50, (256, 256, 170), 9, (256, 256, 180), 21, (256, 256, 184), 3]\n",
      "        20 images converted to PNG\n",
      "        40 images converted to PNG\n",
      "        60 images converted to PNG\n",
      "        80 images converted to PNG\n",
      "        100 images converted to PNG\n",
      "        120 images converted to PNG\n",
      "    [-] Number of images converted to PNG: 127\n",
      "[+] Folder: {'./datasets/Original_zips/ADNI1_Complete_2Yr_1.5T_images/Zip_3'}\n",
      "    [-] Number of files in the folder: 129\n",
      "        20 images loaded\n",
      "        40 images loaded\n",
      "        60 images loaded\n",
      "        80 images loaded\n",
      "        100 images loaded\n",
      "        120 images loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ArrayProxy.__del__ at 0x7fb2ff0a29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/nibabel/arrayproxy.py\", line 168, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [-] Number of images loaded: 129\n",
      "    [-] Shapes of images loaded: [(256, 256, 166), 61, (192, 192, 160), 37, (256, 256, 170), 11, (256, 256, 180), 18, (256, 256, 184), 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-6b31d7e8269d>\", line 25, in <module>\n",
      "    extract_slice(image, title)\n",
      "  File \"/Volumes/HardDrive/TFM/Code/aux_functions/aux_functions_cleaning.py\", line 180, in extract_slice\n",
      "    prob = ext.run(data)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/deepbrain/extractor.py\", line 52, in run\n",
      "    prob = resize(prob, (shape), mode='constant', anti_aliasing=True)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/skimage/transform/_warps.py\", line 186, in resize\n",
      "    coord_map = np.array(np.meshgrid(*coord_arrays,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/nando/opt/anaconda3/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6b31d7e8269d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Get image with multiple slices and save it in PNG format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mextract_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mcount_images\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/HardDrive/TFM/Code/aux_functions/aux_functions_cleaning.py\u001b[0m in \u001b[0;36mextract_slice\u001b[0;34m(image, title)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Calculate probability of being brain tissue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/deepbrain/extractor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_aliasing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         coord_map = np.array(np.meshgrid(*coord_arrays,\n\u001b[0m\u001b[1;32m    187\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for folder in root_nifti_files:\n",
    "    \n",
    "    # Check number of files in the folder\n",
    "    print(f\"[+] Folder:\", {folder})\n",
    "    print(f\"    [-] Number of files in the folder:\", len(os.listdir(folder)))\n",
    "    \n",
    "    # Load zipped 3D Nifti files from the folder\n",
    "    images, titles, shapes = load_images(folder)\n",
    "    print(f\"    [-] Number of images loaded:\", len(images))\n",
    "    print(f\"    [-] Shapes of images loaded:\", shapes)\n",
    "    \n",
    "    # Convert Nifti files to PNG format\n",
    "    count_images = 0  # Initialize images counter\n",
    "\n",
    "    for index, image in enumerate(images):\n",
    "\n",
    "        # Retrieve Image ID from the 3D nitfi file name (from titles list)\n",
    "        title = root_png_images + titles[index].split(\"_\")[-1].split(\".\")[0] + '.png'\n",
    "\n",
    "        if os.path.exists(title):\n",
    "            print(f\"    [-] {title} was already converted to PNG\")\n",
    "            \n",
    "        else:\n",
    "            # Get image with multiple slices and save it in PNG format\n",
    "            extract_slice(image, title)\n",
    "            count_images += 1\n",
    "                \n",
    "        # Print counter status\n",
    "        if(count_images % 20 == 0):\n",
    "            print(f\"        {count_images} images converted to PNG\")\n",
    "            \n",
    "\n",
    "    print(f\"    [-] Number of images converted to PNG:\", count_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skull-stripping\n",
    "Below it can be seen how the skull-stripping process works for each individual Nifti file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Nitfi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where there are the 3D zipped Nifti file of the brain \n",
    "root_nifti_files = path + \"/Datasets/Original_zips/ADNI1_Complete_3Yr_1.5T_images\"\n",
    "file = \"ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20081026123329555_S54061_I123685.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nitfi file\n",
    "image = nib.load(os.path.join(root_nifti_files, file))\n",
    "\n",
    "# Get image data\n",
    "data = image.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect brain mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize brain tissue extractor\n",
    "ext = Extractor()\n",
    "\n",
    "# Calculate probability of being brain tissue\n",
    "prob = ext.run(data) \n",
    "\n",
    "# Extract mask with probability higher than 0.5\n",
    "mask = prob > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract slice before & after skull stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up slice\n",
    "slice_index  = 109\n",
    "slice_original = np.array(data[:, slice_index, :])\n",
    "\n",
    "# Extract slice after skull-stripping \n",
    "slice_cleaned = return_clean_slice(slice_original, slice_index, mask, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot figures with original slice and cleaned slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure\n",
    "fig, axes = plt.subplots(1, 3, figsize = (10, 8))\n",
    "\n",
    "# Plot slice before cleaning\n",
    "axes[0].imshow(slice_original, cmap=\"gray\")\n",
    "axes[0].set_title('Brain slice')\n",
    "\n",
    "# Plot brain mass detected\n",
    "axes[1].imshow(mask[:, slice_index, :], cmap=\"gray\")\n",
    "axes[1].yaxis.set_visible(False)\n",
    "axes[1].set_title('Brain mass')\n",
    "\n",
    "# Plot slice after cleaning\n",
    "axes[2].imshow(slice_cleaned, cmap=\"gray\")\n",
    "axes[2].yaxis.set_visible(False)\n",
    "axes[2].set_title('Cleaned brain slice');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract 3D brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Nitfi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where there are the 3D zipped Nifti file of the brain \n",
    "root_nifti_files = path + \"/datasets/\"\n",
    "file = \"ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070802163833409_S32678_I64025.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nitfi file\n",
    "image = nib.load(os.path.join(root_nifti_files, file))\n",
    "\n",
    "# Get image data\n",
    "data = image.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect brain mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize brain tissue extractor\n",
    "ext = Extractor()\n",
    "\n",
    "# Calculate probability of being brain tissue\n",
    "prob = ext.run(data) \n",
    "\n",
    "# Extract mask with probability higher than 0.5\n",
    "mask = prob > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove skull stripping from brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_cleaned = np.zeros((256,256,166), dtype = \"int16\")\n",
    "\n",
    "for index_i, i in enumerate(data):\n",
    "    for index_j, j in enumerate(i):\n",
    "        for index_k, k in enumerate(j):\n",
    "            \n",
    "            if mask[index_i, index_j, index_k] == True:\n",
    "                brain_cleaned[index_i, index_j, index_k] = data[index_i, index_j, index_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert brain to Nifti file\n",
    "The following site can be used to visualize 3D Nifti files  \n",
    "https://socr.umich.edu/HTML5/BrainViewer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_image = nib.Nifti1Image(brain_cleaned, affine=np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.save(nifti_image, \"nifti_created_2.nii.gz\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nifti files shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(256, 256, 166)\n",
    "ADNI_002_S_0295_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20081026123329555_S54061_I123685.nii.gz\n",
    "\n",
    "(166, 256, 256)\n",
    "ADNI_002_S_1155_MR_MT1__GradWarp__N3m_Br_20120420155919867_S78071_I299371.nii.gz\n",
    "\n",
    "(160, 192, 192)\n",
    "ADNI_003_S_1122_MR_MT1__GradWarp__N3m_Br_20120308102241125_S80176_I288891.nii.gz\n",
    "\n",
    "(256, 256, 170)\n",
    "ADNI_010_S_0419_MR_MPR____N3__Scaled_Br_20091001170206632_S69112_I155919.nii.gz\n",
    "\n",
    "(192, 192, 160)\n",
    "ADNI_011_S_0003_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20080124113450407_S39296_I88252.nii.gz\n",
    "\n",
    "(170, 256, 256)\n",
    "ADNI_012_S_1133_MR_MT1__N3m_Br_20120308102406161_S84881_I288893.nii.gz\n",
    "\n",
    "(256, 256, 180)\n",
    "ADNI_021_S_0141_MR_MPR__GradWarp__N3__Scaled_Br_20090316133310029_S63464_I139026.nii.gz\n",
    "\n",
    "(256, 256, 184)\n",
    "ADNI_032_S_0214_MR_MPR____N3__Scaled_Br_20090420150801593_S63793_I142010.nii.gz\n",
    "\n",
    "(180, 256, 256)\n",
    "ADNI_116_S_1315_MR_MT1__GradWarp__N3m_Br_20120308104543026_S82700_I288917.nii.gz\n",
    "\n",
    "(256, 256, 162)\n",
    "ADNI_136_S_0107_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20091208153924724_S68219_I160555.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Nitfi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where there are the 3D zipped Nifti file of the brain \n",
    "root_nifti_files = path + \"/Datasets/Original_zips/ADNI1_Complete_3Yr_1.5T_images\"\n",
    "file = \"ADNI_002_S_1155_MR_MT1__GradWarp__N3m_Br_20120420155919867_S78071_I299371.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nitfi file\n",
    "image = nib.load(os.path.join(root_nifti_files, file))\n",
    "\n",
    "# Get image data\n",
    "data = image.get_fdata()\n",
    "\n",
    "# Print image shape\n",
    "print(f\"[+] Shapes of image loaded:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define slice to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up slice\n",
    "slice_index  = 60\n",
    "slice_ = np.array(data[:, slice_index, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot figure with 2D slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure\n",
    "fig, axes = plt.subplots(1, 2, figsize = (10, 8))\n",
    "\n",
    "# Plot 2D slice\n",
    "axes[0].imshow(slice_, cmap=\"gray\")\n",
    "axes[0].set_title('Brain slice')\n",
    "\n",
    "rotated_img = ndimage.rotate(slice_, 90)\n",
    "\n",
    "axes[1].imshow(rotated_img, cmap=\"gray\")\n",
    "axes[1].set_title('Brain slice rotated');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO ROTATE\n",
    "(256, 256, 166) - face = 0  - DONE  \n",
    "(256, 256, 170) - face = 0  \n",
    "(192, 192, 160) - face = 0  - DONE (un poco justo de abajo)  \n",
    "(256, 256, 180) - face = 0  \n",
    "(256, 256, 184) - face = 0  - DONE  \n",
    "(256, 256, 162) - face = 0  \n",
    "\n",
    "#### ROTATE\n",
    "(166, 256, 256) - face = 256  - DONE  \n",
    "(160, 192, 192) - face = 192  - DONE   \n",
    "(170, 256, 256) - face = 256  - DONE\n",
    "(180, 256, 256) - face = 256  \n",
    "\n",
    "rotated_img = ndimage.rotate(slice_, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Nitfi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify folders where there are the 3D zipped Nifti file of the brain \n",
    "root_nifti_files = path + \"/Datasets/Original_zips/ADNI1_Complete_3Yr_1.5T_images\"\n",
    "file = \"ADNI_032_S_0214_MR_MPR____N3__Scaled_Br_20090420150801593_S63793_I142010.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nitfi file\n",
    "image = nib.load(os.path.join(root_nifti_files, file))\n",
    "\n",
    "# Print image shape\n",
    "print(f\"[+] Shapes of image loaded:\", image.get_fdata().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract collection of 2D slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extract_slice(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices_matrix_2D(img):\n",
    "    ''' Transform a 3D MRI image into a 2D image, by obtaining 9 slices and placing them in a 4x4 two-dimensional grid.\n",
    "      \n",
    "      All 16 cuts are from a horizontal/axial view. They are selected from the 30th to the 60th level of the original 3D image.\n",
    "      \n",
    "      Parameters:\n",
    "        img -- np.ndarray with the 3D image\n",
    "        \n",
    "      Returns:\n",
    "        np.ndarray -- The resulting 2D image\n",
    "    '''\n",
    "  \n",
    "    # create the final 2D image \n",
    "    image_2D = np.empty(IMG_2D_SHAPE)\n",
    "  \n",
    "    # set the limits and the step\n",
    "    TOP = 60\n",
    "    BOTTOM = 30\n",
    "    STEP = 2\n",
    "    N_CUTS = 8\n",
    "  \n",
    "    # iterator for the cuts\n",
    "    cut_it = TOP\n",
    "    # iterator for the rows of the 2D final image\n",
    "    row_it = 0\n",
    "    # iterator for the columns of the 2D final image\n",
    "    col_it = 0\n",
    "  \n",
    "    for cutting_time in range(N_CUTS):\n",
    "    \n",
    "        # cut\n",
    "        cut = img[:, cut_it, :]\n",
    "        cut_it -= STEP\n",
    "    \n",
    "        # reset the row iterator and move the\n",
    "        # col iterator when needed\n",
    "        if cutting_time in [2, 4, 8]:\n",
    "            row_it = 0\n",
    "            col_it += cut.shape[1]\n",
    "    \n",
    "        # copy the cut to the 2D image\n",
    "        for i in range(cut.shape[0]):\n",
    "            for j in range(cut.shape[1]):\n",
    "                image_2D[i + row_it, j + col_it] = cut[i, j]\n",
    "    \n",
    "        row_it += cut.shape[0]\n",
    "        print(cutting_time)\n",
    "  \n",
    "    # return the final 2D image, with 3 channels\n",
    "    # this is necessary for working with most pre-trained nets\n",
    "    return np.repeat(image_2D[None, ...], 3, axis=0).T\n",
    "    #return image_2D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
