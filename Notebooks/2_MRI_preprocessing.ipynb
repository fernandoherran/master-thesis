{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from deepbrain import Extractor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_theme(context='notebook')\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(file):\n",
    "    \"\"\"\n",
    "    Read and load nifti file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read file\n",
    "    volume = nib.load(file)\n",
    "    \n",
    "    # Get raw data\n",
    "    volume = volume.get_fdata()\n",
    "    \n",
    "    # Exchange axis 0 and 2\n",
    "    if volume.shape[1] == volume.shape[2]:\n",
    "        print(f\"{file} has a shape incompatible\")\n",
    "    \n",
    "    return volume\n",
    "\n",
    "\n",
    "def remove_skull(volume):\n",
    "    \"\"\"\n",
    "    Extract only brain mass from volume.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize brain tissue extractor\n",
    "    ext = Extractor()\n",
    "\n",
    "    # Calculate probability of being brain tissue\n",
    "    prob = ext.run(volume) \n",
    "\n",
    "    # Extract mask with probability higher than 0.5\n",
    "    mask = prob > 0.5\n",
    "    \n",
    "    # Detect only pixels with brain mass\n",
    "    volume [mask == False] = 0\n",
    "    volume = volume.astype(\"float32\")\n",
    "    \n",
    "    return volume\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"\n",
    "    Normalize the volume intensity.\n",
    "    \"\"\"\n",
    "    \n",
    "    I_min = np.amin(volume)\n",
    "    I_max = np.amax(volume)\n",
    "    new_min = 0.0\n",
    "    new_max = 1.0\n",
    "    \n",
    "    volume_nor = (volume - I_min) * (new_max - new_min)/(I_max - I_min)  + new_min\n",
    "    volume_nor = volume_nor.astype(\"float32\")\n",
    "    \n",
    "    return volume_nor\n",
    "\n",
    "\n",
    "def cut_volume(volume):\n",
    "    \"\"\"\n",
    "    Cut size of 3D volume.\n",
    "    \"\"\"\n",
    "    \n",
    "    if volume.shape[0] == 256:\n",
    "        volume_new = volume[20:220,30:,:]\n",
    "    \n",
    "    if volume.shape[0] == 192:\n",
    "        volume_new = volume[20:180,20:180,:]\n",
    "    \n",
    "    return volume_new\n",
    "\n",
    "\n",
    "def resize_volume(volume):\n",
    "    \"\"\"\n",
    "    Resize across z-axis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the desired depth\n",
    "    desired_height = 180\n",
    "    desired_width = 180\n",
    "    desired_depth = 110\n",
    "    \n",
    "    # Get current depth\n",
    "    current_height = volume.shape[0]\n",
    "    current_width = volume.shape[1]\n",
    "    current_depth = volume.shape[2]\n",
    "    \n",
    "    # Compute depth factor\n",
    "    height = current_height / desired_height\n",
    "    width = current_width / desired_width\n",
    "    depth = current_depth / desired_depth\n",
    "\n",
    "    height_factor = 1 / height\n",
    "    width_factor = 1 / width\n",
    "    depth_factor = 1 / depth\n",
    "    \n",
    "    # Rotate\n",
    "    #img = ndimage.rotate(img, 90, reshape=False)\n",
    "    \n",
    "    # Resize across z-axis\n",
    "    volume = ndimage.zoom(volume, (height_factor, width_factor, depth_factor), order=1)\n",
    "    \n",
    "    return volume\n",
    "\n",
    "\n",
    "def save_matrix(volume, file, save_path = \"./Volume_files/\"):\n",
    "    \"\"\"\n",
    "    Save 3D matrix into numpy file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if save_path folder exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)   \n",
    "\n",
    "    # Get Image ID from path\n",
    "    title = file.split(\"_\")[-1].split(\".\")[0]\n",
    "    \n",
    "    # Save volume array\n",
    "    if os.path.exists(save_path + title + \".npz\"):\n",
    "        print(f\"    {title} was already processed.\")\n",
    "    else:\n",
    "        np.savez_compressed(save_path + title, volume)\n",
    "    \n",
    "\n",
    "def process_scan(file, save_path):\n",
    "    \"\"\"\n",
    "    Read, skull stripping and resize Nifti file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read Nifti file\n",
    "    volume = read_nifti_file(file)\n",
    "    \n",
    "    # Extract skull from 3D volume\n",
    "    volume = remove_skull(volume)\n",
    "    \n",
    "    # Cut 3D volume\n",
    "    #volume = cut_volume(volume)\n",
    "    \n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    \n",
    "    # Normalize pixel intensity\n",
    "    volume = normalize(volume)\n",
    "    \n",
    "    # Save 3D matrix\n",
    "    save_matrix(volume, file, save_path)\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path_mri = [\"../Datasets/Files_network/\"]\n",
    "save_path = \"../Datasets/Volume_files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load list of Images IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_titles_path = '../Datasets/list_titles_cleaned.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_titles = np.load(list_titles_path, allow_pickle= True)\n",
    "list_titles = list_titles['arr_0']\n",
    "list_titles = list(list_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Current path: ../Datasets/Files_network/\n",
      "WARNING:tensorflow:From /Users/nando/opt/anaconda3/lib/python3.8/site-packages/deepbrain/extractor.py:19: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "    50 volumes processed\n",
      "    100 volumes processed\n",
      "    150 volumes processed\n",
      "    200 volumes processed\n",
      "    250 volumes processed\n",
      "    300 volumes processed\n",
      "    350 volumes processed\n",
      "    400 volumes processed\n",
      "    450 volumes processed\n",
      "    500 volumes processed\n",
      "    550 volumes processed\n",
      "    600 volumes processed\n",
      "    650 volumes processed\n",
      "    700 volumes processed\n",
      "    750 volumes processed\n",
      "    800 volumes processed\n",
      "    850 volumes processed\n",
      "    900 volumes processed\n",
      "    950 volumes processed\n",
      "    1000 volumes processed\n",
      "    1050 volumes processed\n",
      "[+] Total number of volumes processed: 1085\n",
      "\n",
      "[+] Time of process: 7981.61\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "count_volumes = 0\n",
    "\n",
    "for path in list_path_mri:\n",
    "    \n",
    "    print(\"[+] Current path:\", path)\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        # Avoid trigerring .DS_Store (when use macOS)\n",
    "        if file.startswith('.DS_Store'):\n",
    "            continue\n",
    "        \n",
    "        title = file.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "        if title in list_titles:\n",
    "            \n",
    "            # Volume process\n",
    "            volume = process_scan(path + file, save_path)\n",
    "\n",
    "            count_volumes += 1\n",
    "\n",
    "            # Print counter status\n",
    "            if(count_volumes % 50 == 0):\n",
    "                print(f\"    {count_volumes} volumes processed\")\n",
    "        \n",
    "print(\"[+] Total number of volumes processed:\", count_volumes)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\n[+] Time of process: \"+\"{:.2f}\".format(end_time-start_time));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "shapes = []\n",
    "counters = [0] * 30\n",
    "titles_shapes = [[] for i in range(30)]\n",
    "\n",
    "for index, file in enumerate(os.listdir(new_path)):\n",
    "    \n",
    "    # Avoid trigerring .DS_Store (when use macOS)\n",
    "    if subpath.startswith('.DS_Store'):\n",
    "        continue\n",
    "    \n",
    "    # Read Nifti file\n",
    "    volume = read_nifti_file(new_path + file)\n",
    "    \n",
    "    if volume.shape not in shapes:\n",
    "        shapes.append(volume.shape)\n",
    "    \n",
    "    index_shapes = shapes.index(volume.shape)\n",
    "    \n",
    "    counters[index_shapes] += 1 \n",
    "    \n",
    "    titles_shapes[index_shapes].append(file.split(\"_\")[-1].split(\".\")[0])\n",
    "    \n",
    "    if index % 50 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shapes_cleaned = [shape_ for index, shape_ in enumerate(shapes) if counters[index] > 30]\n",
    "list_counters_cleaned = [counter_ for index, counter_ in enumerate(counters) if counters[index] > 30]\n",
    "list_titles_cleaned = [title_ for index, title_ in enumerate(titles_shapes) if counters[index] > 30]\n",
    "list_titles_cleaned = [item for sublist in list_titles_cleaned for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "711 from 1100 has shape (256,256) = 64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_shapes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counters_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show initial image before being resized\n",
    "image_ = volume[:,:,40]\n",
    "print(\"[+] Shape of the image:\", image_.shape)\n",
    "plt.figure(figsize = (5, 4))\n",
    "plt.imshow(image_, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 180\n",
    "width = 180\n",
    "depth = volume.shape[2]\n",
    "\n",
    "volume_resized = np.zeros((height, width, depth))\n",
    "\n",
    "for index in range(depth):\n",
    "    \n",
    "    # Get 2D slice\n",
    "    image = volume[:, :, index]\n",
    "    \n",
    "    # Resize 2D slice\n",
    "    image_resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    volume_resized[:, :, index] = image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 180\n",
    "width = 180\n",
    "depth = 100\n",
    "\n",
    "volume_resized_2 = np.zeros((height, width, depth))\n",
    "\n",
    "for index in range(width):\n",
    "    \n",
    "    # Get 2D slice\n",
    "    image = volume_resized[:, index, :]\n",
    "    \n",
    "    # Resize 2D slice\n",
    "    image_resized = cv2.resize(image, (depth, height), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    volume_resized_2[:, index, :] = image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load volume array\n",
    "volume_loaded_2 = np.load(save_path + \"MR.npz\" , allow_pickle= True)\n",
    "volume_loaded_2 = volume_loaded_2['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save volume as nifti file\n",
    "nifti_image = nib.Nifti1Image(volume_loaded , affine=np.eye(4))\n",
    "nib.save(nifti_image, \"../Datasets/nifti_created_10.nii.gz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.thepythoncode.com/article/contour-detection-opencv-python\n",
    "# Get 2D slice\n",
    "image_slice = volume[:,:,60]\n",
    "image_slice = np.float32(image_slice)\n",
    "data = im.fromarray(image_slice)\n",
    "\n",
    "# Create a binary thresholded image\n",
    "_, binary = cv2.threshold(np.float32(data), 0.5, 1, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(image = np.array(binary, dtype=np.int32),  \n",
    "                                       mode = cv2.RETR_FLOODFILL, \n",
    "                                       method = cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours\n",
    "cnt = contours[4]\n",
    "image_contours = cv.drawContours(np.float32(data), [cnt], 0, (0,255,0), 3)\n",
    "plt.imshow(image_contours, c)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
